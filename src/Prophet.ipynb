{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to execute Prophet and generate an output file highlighting anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importing all the required libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The purpose of this section is to read a csv file that can be used as an input for the anomaly detection function.\n",
    "We start with the cleaned NYCHA dataset, delete all rows where consumption values are missing (0), and filter for those accounts which have atleast 50 rows of data. Finally all the unwanted columns are dropped leaving us with just 3 columns, Building_id/Account no, Month and Consumption. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycha = pd.read_csv(\"../output/nycha/NYCHA_TS.csv\", parse_dates=['Month'])\n",
    "nycha = nycha.fillna(0)\n",
    "nycha_f = nycha[nycha['Value'] != 0]\n",
    "nycha_f = nycha_f.drop('Unnamed: 0', axis=1)\n",
    "nycha_f = nycha_f.groupby('Account').filter(lambda x: len(x) > 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** The function to automate the generation of a dataframe indicating anomalies using Prophet. <br>\n",
    "The input to this function is the list of building account ids from which anomalies need to be detected **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_prophet(b_id):\n",
    "    # filter the data for this account\n",
    "    prop_df = nycha_f[nycha_f['Account'] == b_id]\n",
    "    # drop and rename the columns as required by Prophet\n",
    "    prop_df = prop_df.drop('Account', axis = 1)\n",
    "    prop_df = prop_df.rename(columns={'Month':'ds', 'Value':'y'})\n",
    "    # create a copy of the original dataframe\n",
    "    prop_df_o = prop_df.copy()\n",
    "    # set the month as index\n",
    "    prop_df_o = prop_df_o.set_index('ds')\n",
    "    # run the prophet model with yearly seasonality, interval width or confidence interval is set to 95% to \n",
    "    # increase the sampling threshold, mcmc sample size of 50 performs full Bayesian sampling to include uncertainty\n",
    "    # in seasonality\n",
    "    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False, interval_width=0.95, mcmc_samples=50)\n",
    "    # fit the model using original dataset\n",
    "    model.fit(prop_df)\n",
    "    # get predicted values for the entire dataset\n",
    "    predicted = model.predict()\n",
    "    # the resulting dataframe has many columns, here we filter the important ones from it.\n",
    "    actvpred = predicted[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    # get the original values for consumption \n",
    "    actvpred.loc[:,'y_orig'] = prop_df_o.values\n",
    "    # identify anomalies based on whether the original value lies in the given threshold (between yhat_lower and yhat_upper) \n",
    "    actvpred.loc[:,'Anomaly'] = np.where((actvpred['y_orig'] >= actvpred['yhat_lower']) & (actvpred['y_orig'] <= actvpred['yhat_upper']), 'No', 'Yes')\n",
    "    # add a column to indicate the building id in the resulting dataframe\n",
    "    actvpred['b_id'] = b_id\n",
    "    return actvpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This section of code is to call the function created above, by first aggregating all the account numbers in a list and using that as an input parameter for the function.\n",
    "Once the resulting dataframe is returned from the function, we export this data to a csv file. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all the unique account ids from the data\n",
    "b_m = np.unique(nycha_f['Account'])\n",
    "# convert this to a list and then Series\n",
    "m_list = b_m.tolist()\n",
    "build_meter = pd.Series(m_list)\n",
    "# initialize the columns to be used in the final dataframe\n",
    "col = ['Build_id','Month','Predicted','Original','Upper_b','Lower_b','Anomaly']\n",
    "# initialize a new dataframe with the column names from above\n",
    "df_new = pd.DataFrame(columns = col)\n",
    "# run a loop for all the accounts\n",
    "for i in build_meter:\n",
    "    # call the function\n",
    "    res = automate_prophet(i)\n",
    "    # rename the columns in the dataframe returned to match the column names above\n",
    "    res = res.rename(columns={\"ds\":\"Month\",\"yhat\":\"Predicted\",\"yhat_lower\":\"Lower_b\",\"yhat_upper\":\"Upper_b\",\"y_orig\":\"Original\",\"b_id\":\"Build_id\"})\n",
    "    # reorder the columns as specified\n",
    "    res = res[['Build_id','Month','Predicted','Original','Upper_b','Lower_b','Anomaly']]\n",
    "    # append this dataframe to the result\n",
    "    df_new = pd.concat([df_new,res],ignore_index=True)\n",
    "# write the output to a csv file\n",
    "df_new.to_csv('../output/nycha/final_output_prophet.csv', header=True, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
