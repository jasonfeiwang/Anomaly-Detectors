{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prorated_imputed = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_prorated_kwh_imputed\")\n",
    "df_prorated_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_building = df_prorated_imputed[df_prorated_imputed['Building_Meter']=='165.0 - BLD 03_90327795']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_building = df_one_building.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_chunker(data, window_len, slide_len):\n",
    "    \"\"\"\n",
    "    Split a list into a series of sub-lists, each sub-list window_len long,\n",
    "    sliding along by slide_len each time. If the list doesn't have enough\n",
    "    elements for the final sub-list to be window_len long, the remaining data\n",
    "    will be dropped.\n",
    "    e.g. sliding_chunker(range(6), window_len=3, slide_len=2)\n",
    "    gives [ [0, 1, 2], [2, 3, 4] ]\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for pos in range(0, len(data), slide_len):\n",
    "        chunk = np.copy(data[pos:pos+window_len])\n",
    "        if len(chunk) != window_len:\n",
    "            continue\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_waves(waves, step):\n",
    "    \"\"\"\n",
    "    Plot a set of 9 waves from the given set, starting from the first one\n",
    "    and increasing in index by 'step' for each subsequent graph\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    n_graph_rows = 3\n",
    "    n_graph_cols = 3\n",
    "    graph_n = 1\n",
    "    wave_n = 0\n",
    "    for _ in range(n_graph_rows):\n",
    "        for _ in range(n_graph_cols):\n",
    "            axes = plt.subplot(n_graph_rows, n_graph_cols, graph_n)\n",
    "            axes.set_ylim([min(df_one_building['Imputed_KWH'])-10000, max(df_one_building['Imputed_KWH'])+10000])\n",
    "            plt.plot(waves[wave_n])\n",
    "            graph_n += 1\n",
    "            wave_n += step\n",
    "    # fix subplot sizes so that everything fits\n",
    "    plt.suptitle('Waveform Segments of 8 data points')\n",
    "    plt.tight_layout(pad=2,h_pad=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct(data, window, clusterer):\n",
    "    \"\"\"\n",
    "    Reconstruct the given data using the cluster centers from the given\n",
    "    clusterer.\n",
    "    \"\"\"\n",
    "    window_len = len(window)\n",
    "    slide_len = window_len/2\n",
    "    segments = sliding_chunker(data, window_len, slide_len)\n",
    "    reconstructed_data = np.zeros(len(data))\n",
    "    for segment_n, segment in enumerate(segments):\n",
    "        # window the segment so that we can find it in our clusters which were\n",
    "        # formed from windowed data\n",
    "        segment *= window\n",
    "        nearest_match_idx = clusterer.predict(segment)[0]\n",
    "        nearest_match = np.copy(clusterer.cluster_centers_[nearest_match_idx])\n",
    "\n",
    "        pos = segment_n * slide_len\n",
    "        reconstructed_data[pos:pos+window_len] += nearest_match\n",
    "\n",
    "    return reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_len = 8\n",
    "slide_len = 1\n",
    "\n",
    "segments = []\n",
    "for start_pos in range(0, len(df_one_building['Imputed_KWH']), slide_len):\n",
    "    end_pos = start_pos + segment_len\n",
    "    # make a copy so changes to 'segments' doesn't modify the original data\n",
    "    segment = np.copy(df_one_building['Imputed_KWH'][start_pos:end_pos])\n",
    "    # if we're at the end and we've got a truncated segment, drop it\n",
    "    if len(segment) != segment_len:\n",
    "        continue\n",
    "    segments.append(segment)\n",
    "\n",
    "print(\"Produced %d waveform segments\" % len(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_waves(segments, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters=12)\n",
    "clusterer.fit(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_waves(clusterer.cluster_centers_, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slide_len = 1\n",
    "test_segments = sliding_chunker(\n",
    "    df_one_building['Imputed_KWH'],\n",
    "    window_len=segment_len,\n",
    "    slide_len=slide_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroids = clusterer.cluster_centers_\n",
    "\n",
    "segment = np.copy(test_segments[16])\n",
    "# predict() returns a list of centres to cope with the possibility of multiple\n",
    "# samples being passed\n",
    "nearest_centroid_idx = clusterer.predict(test_segments[16].reshape(1,-1))[0]\n",
    "nearest_centroid = np.copy(centroids[nearest_centroid_idx])\n",
    "plt.figure()\n",
    "plt.plot(segment, label=\"Original segment\");\n",
    "plt.plot(nearest_centroid, label=\"Nearest centroid\");\n",
    "plt.title('Comparison of original and predicted at index 8');\n",
    "plt.xlabel('Index within each segment');\n",
    "plt.ylabel('Imputed KWH Consumption');\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df_one_building['Imputed_KWH']\n",
    "reconstruction = np.zeros(len(data))\n",
    "\n",
    "\n",
    "for segment_n, segment in enumerate(test_segments):\n",
    "    # don't modify the data in segments\n",
    "    segment = np.copy(segment)\n",
    "    nearest_centroid_idx = clusterer.predict(segment.reshape(1,-1))[0]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    nearest_centroid = np.copy(centroids[nearest_centroid_idx])\n",
    "    \n",
    "    # overlay our reconstructed segments with an overlap of half a segment\n",
    "    pos = int(segment_n * slide_len)\n",
    "    reconstruction[pos:pos+segment_len] += nearest_centroid/(segment_len/slide_len)\n",
    "#     if 8 >= pos and 8 < pos+segment_len:\n",
    "#          plt.plot(np.linspace(0,7,8)+pos, nearest_centroid,label = pos)\n",
    "\n",
    "# fix first segment_len and last segment_len data points since they are not modeled segment_len/slide_len times\n",
    "for i in np.linspace(0,segment_len-1,segment_len).astype(int):\n",
    "    reconstruction[i] = reconstruction[i]/(i+1)*(segment_len/slide_len)\n",
    "    reconstruction[-i -1 ] = reconstruction[-i - 1]/(i+1)*(segment_len/slide_len)\n",
    "\n",
    "n_plot_samples = len(data)\n",
    "error = reconstruction[0:n_plot_samples] - data[0:n_plot_samples]\n",
    "error_99th_percentile = np.percentile(error, 99)\n",
    "print(\"Maximum reconstruction error was %.1f\" % error.max())\n",
    "print(\"99th percentile of reconstruction error was %.1f\" % error_99th_percentile)\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(data[0:n_plot_samples], label=\"Original_Data\")\n",
    "plt.plot(reconstruction[0:n_plot_samples], label=\"Reconstructed_Value\")\n",
    "plt.plot(np.abs(error[0:n_plot_samples]), label=\"Abs Reconstruction_Error\")\n",
    "plt.title('Reconstructed Data vs. Original Data');\n",
    "plt.xlabel('Index within each account');\n",
    "plt.ylabel('Imputed KWH Consumption');\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.abs(error[0:n_plot_samples]), label=\"Reconstruction Error\")\n",
    "plt.axhline(y=error_99th_percentile,linestyle='--',color='gray');\n",
    "plt.title('Abs Reconstruction error with 99th percentile error threshold');\n",
    "plt.xlabel('Index within each account');\n",
    "plt.ylabel('Reconstruction_Error');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_entries = df_one_building[np.abs(error[0:n_plot_samples])>error_99th_percentile]\n",
    "anomaly_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_one_building['Anomaly'] = np.where(np.abs(error[0:n_plot_samples])>error_99th_percentile, 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = df_one_building[df_one_building['Anomaly']=='Yes'][['Building_Meter','Month','Month_Type','Imputed_KWH','Anomaly']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output['Reconstruction_Error'] = error[df_one_building['Anomaly']=='Yes']\n",
    "output['Reconstructed_Value'] = reconstruction[df_one_building['Anomaly']=='Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output[['Building_Meter','Month','Imputed_KWH','Reconstructed_Value','Reconstruction_Error','Anomaly']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
