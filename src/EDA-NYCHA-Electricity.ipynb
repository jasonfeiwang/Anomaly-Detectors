{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as pdsql\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Setup matplotlib to display in notebook:\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/NYC Open Data - Electric_Consumption_And_Cost__2010_-__June_2018_.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of empty values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - General Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (pd.isna(df['Account Name']) == True)\n",
    "df.drop(mask[mask == True].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove rows where electricity charges were estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['Estimated'] == 'Y         '].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change column names for easy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Development_Name', 'Borough', 'Account_Name', 'Location', 'Meter_AMR',\n",
    "       'Meter_Scope', 'TDS #', 'EDP', 'RC_Code', 'Funding_Source', 'AMP #',\n",
    "       'Vendor_Name', 'UMIS_BILL_ID', 'Revenue_Month', 'Service_Start_Date',\n",
    "       'Service_End_Date', '# days', 'Meter_Number', 'Estimated',\n",
    "       'Current_Charges', 'Rate_Class', 'Bill_Analyzed', 'Consumption_KWH',\n",
    "       'KWH_Charges', 'Consumption_KW', 'KW_Charges', 'Other_Charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Type Converstion\n",
    "\n",
    "1. Change the following fields from string to numerical:\n",
    "    - \"Consumption_KW\", \"Current_Charges\", \"KWH_Charges\", \"KW_Charges\", \"Other_Charges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Consumption_KW\"] = df[\"Consumption_KW\"].apply(lambda x: x.replace(\",\",\"\") if type(x) == str else str(x))\n",
    "df[\"Consumption_KW\"] = df[\"Consumption_KW\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Current_Charges\"] = df[\"Current_Charges\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\").replace(\"(\",\"-\").replace(\")\",\"\") if type(x) == str else str(x))\n",
    "df[\"Current_Charges\"] = df[\"Current_Charges\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"KWH_Charges\"] = df[\"KWH_Charges\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\").replace(\"(\",\"-\").replace(\")\",\"\") if type(x) == str else str(x))\n",
    "df[\"KWH_Charges\"] = df[\"KWH_Charges\"].astype(float, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"KW_Charges\"] = df[\"KW_Charges\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\").replace(\"(\",\"-\").replace(\")\",\"\") if type(x) == str else str(x))\n",
    "df[\"KW_Charges\"] = df[\"KW_Charges\"].astype(float, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Other_Charges\"] = df[\"Other_Charges\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\").replace(\"(\",\"-\").replace(\")\",\"\") if type(x) == str else str(x))\n",
    "df[\"Other_Charges\"] = df[\"Other_Charges\"].astype(float, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More than 25% of the values for all except \"Curent Charges\" are 0, which seem unusual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Consumption_KWH\",  \"Consumption_KW\", \"Current_Charges\", \"KWH_Charges\", \"KW_Charges\", \"Other_Charges\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Unify the format of \"Meter_Number\" field (some values exists in both numerical and string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Meter_Number'] = df['Meter_Number'].apply(lambda x: str(x) if type(x) == int else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Convert Revenue_Month and Two dates to datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Revenue_Month\"] = df[\"Revenue_Month\"].map(lambda x: datetime.strptime(x.split(\" \")[0], '%m/%d/%Y'))\n",
    "df['Service_Start_Date'] = df['Service_Start_Date'].map(lambda x: datetime.strptime(x, '%m/%d/%Y'))\n",
    "df['Service_End_Date'] = df['Service_End_Date'].map(lambda x: datetime.strptime(x, '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In some cases the Revenue_Month is not in the same revenue_year as the Service Start and End dates when those two are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date_year'] = df['Service_Start_Date'].apply(lambda x: datetime(x.year, 1, 1))\n",
    "\n",
    "df['end_date_year'] = df['Service_End_Date'].apply(lambda x: datetime(x.year, 1, 1))\n",
    "\n",
    "df['revenue_month_year'] = df['Revenue_Month'].apply(lambda x: datetime(x.year, 1, 1))\n",
    "\n",
    "mask = ((df['end_date_year'] == df['start_date_year']) & (df['revenue_month_year'] != df['end_date_year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask][['Revenue_Month', 'Service_Start_Date', 'Service_End_Date', 'Meter_Number']].sort_values(['Revenue_Month', 'Service_Start_Date', 'Meter_Number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the cases where Revenue_Month is in the wrong year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, \"Revenue_Month\"] = datetime.strptime('10/01/2010', '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Clean up the Meter_Number field\n",
    "- remove the leadng zeros \n",
    "- remove white spaces\n",
    "- standardize the format for meter_numbers of the similar pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Meter_Number'] = df['Meter_Number'].apply(lambda x: x.lstrip(\"0\").strip(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Meter_Length'] = df['Meter_Number'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Meter_Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Meter_Length'] == 12]['Meter_Number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Meter_Number'] == '1096662 41-5', 'Meter_Number'] = '1096662-41.5'\n",
    "\n",
    "df.loc[df['Meter_Number'] == '1096662 58-5', 'Meter_Number'] = '1096662-58.5'\n",
    "\n",
    "df.loc[df['Meter_Number'] == '8096662 41-5', 'Meter_Number'] = '8096662-41.5'\n",
    "\n",
    "df.loc[df['Meter_Number'] == '8096662 58-5', 'Meter_Number'] = '8096662-58.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check \"Meter Scope\": Do the row with a range value represent a \"Master Meter\" (i.e. its value is the sum of other related rows)? - No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df['Meter Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df[(df['TDS #'] == 118) & (df[\"Revenue_Month\"] == '2010-02-01')][[\"Location\", \"Meter Scope\", \"Revenue_Month\", \"Current_Charges\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df[(df['Meter Scope'] == 'Community Center')].groupby('Location').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df[(df['Meter Scope'] == 'BLD 1 - 9')].groupby('Location').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create an unique identifier for each building and remove unnecessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combination of TDS# and Location uniquely determines a buildling\n",
    "# Use EDP or RC Code when TDS# is not available\n",
    "df['Building_ID'] = df['TDS #'].combine_first(df['EDP']).map(str).combine_first(df['RC_Code']) \\\n",
    "                    + \" - \" + df['Location'].map(lambda x: 'NA' if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building_ID alone is not the primary key of the data\n",
    "df.groupby(['Building_ID', 'Revenue_Month']).count().shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combination of Building_ID, meter number and revenue month is still not a primary key\n",
    "df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month']).count().shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of columns of interest\n",
    "cols = ['Account_Name', 'Location', 'Building_ID', 'Meter_Number',\n",
    "        'Revenue_Month', 'Service_Start_Date', 'Service_End_Date', '# days', \n",
    "       'Current_Charges','Consumption_KWH', 'KWH_Charges',\n",
    "       'Consumption_KW', 'KW_Charges', 'Other_Charges']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combination of Building_ID, meter number and revenue month is almost a primary key\n",
    "df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month', 'Service_Start_Date', 'Service_End_Date']).count().shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Drop Duplicated rows and clean up to format of Meter_Number field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Check which combinations of the 5 fields (Building_ID, Meter, Month, StartDate, EndDate) has multiple rows and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month', 'Service_Start_Date', 'Service_End_Date']).count()['Account_Name'].reset_index()\n",
    "idx.columns = ['Building_ID', 'Meter_Number', 'Revenue_Month','Service_Start_Date', 'Service_End_Date', 'Counts']\n",
    "idx = idx[idx['Counts'] > 1]\n",
    "\n",
    "dupRows = idx.sort_values('Counts', ascending = False)\n",
    "\n",
    "a = pd.merge(dupRows.iloc[:, 0:3], df[cols], on = \\\n",
    "         ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'inner')[cols]\\\n",
    "        .sort_values(['Building_ID', 'Meter_Number', 'Revenue_Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### half of these problematic rows has zero values in the numerical fields of charges and consumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove those rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Current_Charges'] == 0) & (df['KWH_Charges'] == 0) & (df['KW_Charges'] == 0) \\\n",
    "  & (df['Other_Charges'] == 0) & (df['Consumption_KWH'] == 0) & (df['Consumption_KW'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we also don't care about entries that only has other_charges not equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Other_Charges'] != 0) & (df['KWH_Charges'] == 0) & (df['KW_Charges'] == 0) \\\n",
    "  & (df['Consumption_KWH'] == 0) & (df['Consumption_KW'] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month', 'Service_Start_Date', 'Service_End_Date']).count()['Account_Name'].reset_index()\n",
    "idx.columns = ['Building_ID', 'Meter_Number', 'Revenue_Month','Service_Start_Date', 'Service_End_Date', 'Counts']\n",
    "idx = idx[idx['Counts'] > 1]\n",
    "\n",
    "dupRows = idx.sort_values('Counts', ascending = False)\n",
    "\n",
    "a = pd.merge(dupRows.iloc[:, 0:3], df[cols], on = \\\n",
    "         ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'inner')[cols]\\\n",
    "        .sort_values(['Building_ID', 'Meter_Number', 'Revenue_Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 2 rows left, seems a case of rebilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. save a copy of the original dataframe before further data cleaning with alterations and flag the rows with problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['flag'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_orig.iloc[:, 0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update the flag in df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_orig['Building_ID'] == '63.0 - BLD 11') & (df_orig['Meter_Number'] == '8125318') & (df_orig['Revenue_Month'] == '2011-10-01')\n",
    "df_orig.loc[mask, 'flag'] = 'rebill'\n",
    "df_orig = df_orig.iloc[:, 0:15]\n",
    "df_orig.flag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the entries with rebilling from the working dataset df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Add a column for Revenue_Year and reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'Revenue_Year'] = df['Revenue_Month'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ordered = ['Account_Name', 'Location', 'Building_ID', 'Meter_Number',\n",
    "       'Revenue_Month', 'Revenue_Year', 'Service_Start_Date', 'Service_End_Date',\n",
    "       '# days', 'Consumption_KW', 'KW_Charges', \n",
    "       'Consumption_KWH', 'KWH_Charges', 'Other_Charges', 'Current_Charges']\n",
    "\n",
    "df = df[col_ordered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Data Cleaning with alterations - aggregation, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Check the zero values in Current_Charges, KWH_Charges and KW_Charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Percentage of rows have current_charges == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"{:.2%}\".format(df[df['Current_Charges'] == 0].shape[0]/df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when current_charges == 0, all kwh_charges == 0 (NaN correlation coefficients with all other variables) and kw_charges seems negatively correlated with other_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Current_Charges'] == 0][['KWH_Charges', 'KW_Charges', 'KWH_Charges', 'Other_Charges']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when current_charges == 0, 82% of the time kw_charges == - other_charges and kw_charges ==  other_charges otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Other_Charges'] + df['KW_Charges'] == 0) & (df['Current_Charges'] == 0) & (df['KWH_Charges'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:.2%}\".format(df[mask].shape[0]/df[df['Current_Charges'] == 0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Current_Charges'] == 0) & ((df['Other_Charges'] == df['KW_Charges']) \\\n",
    "        | (df['Other_Charges'] + df['KW_Charges'] == 0))].shape[0] / \\\n",
    "df[df['Current_Charges'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correct the rows where Other_Charges == KW_Charges with Other_Charges = -KW_Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Current_Charges'] == 0) & ((df['Other_Charges'] == df['KW_Charges']) & (df['KW_Charges'] != 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, 'KW_Charges'] = df.loc[mask, 'Other_Charges'] * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Current_Charges'] == 0][['Current_Charges', 'KW_Charges', 'KWH_Charges', 'Other_Charges']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Current_Charges'] == 0][['Current_Charges', 'KW_Charges', 'KWH_Charges', 'Other_Charges']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update the flag in df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_orig['Current_Charges'] == 0) & ((df_orig['Other_Charges'] == df_orig['KW_Charges']) & (df_orig['KW_Charges'] != 0))\n",
    "valid = df_orig[mask]['flag']\n",
    "df_orig.loc[mask, 'flag'] = valid.apply(lambda x: 'Sign of Other_Charges is incorrect' if x == \"\" else x + '; ' + 'Sign of Other_Charges is incorrect')\n",
    "\n",
    "df_orig = df_orig.iloc[:, 0:15]\n",
    "\n",
    "del( valid, mask)\n",
    "df_orig.flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics regarding zero-values and meter types - 1st time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select Building_ID, Meter_Number \\\n",
    "        , sum(case when KWH_Charges == 0 and KW_Charges > 0 then 1 else 0 end) as count_kw_only \\\n",
    "        , sum(case when KW_Charges == 0 and KWH_Charges > 0 then 1 else 0 end) as count_kwh_only \\\n",
    "        , sum(Current_Charges) as total_current_charges \\\n",
    "        , count(*) as count \\\n",
    "        from df \\\n",
    "        group by df.Building_ID, df.Meter_Number\"\n",
    "df_meter_type = pysql(str1)\n",
    "\n",
    "\n",
    "df_meter_type['kwh_only'] = ((df_meter_type['count_kwh_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kw_only'] == 0)\n",
    "df_meter_type['kw_only'] = ((df_meter_type['count_kw_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kwh_only'] == 0)\n",
    "\n",
    "#### check the meters\n",
    "\n",
    "print(\"perc of kw_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kw_only'] == 1) & (df_meter_type['kwh_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 1) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_and_kw meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 0) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "\n",
    "#### check the building_ids\n",
    "\n",
    "a = df_meter_type[df_meter_type['kwh_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "b =  df_meter_type[df_meter_type['kw_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "a.columns = ['Building_ID', 'Count']\n",
    "b.columns = ['Building_ID', 'Count']\n",
    "\n",
    "print(\"perc of buildings with both kw_only and kwh_only meters:\", \\\n",
    "     \"{:.2%}\".format(pd.merge(a, b, on = 'Building_ID', how = 'inner').shape[0] \\\n",
    "/ df_meter_type.groupby(['Building_ID']).agg('count').reset_index().shape[0]))\n",
    "\n",
    "\n",
    "#### Check the statistics of zero-value rows:\n",
    "\n",
    "print(\"perc of rows - current charges of zero:\", \"{:.2%}\".format(df[df['Current_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kw charges of zero:\", \"{:.2%}\".format(df[df['KW_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kwh charges of zero:\", \"{:.2%}\".format(df[df['KWH_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KWH_Charges'] == 0) ^ (df['Consumption_KWH'] == 0)) \\\n",
    "   | ((df['KW_Charges'] == 0) ^ (df['Consumption_KW'] == 0)) ].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - sum of charges inconsistency:\", \\\n",
    "     \"{:.2%}\".format(1 - df[df['Current_Charges'] == df['KWH_Charges'] + df['KW_Charges'] + df['Other_Charges']].shape[0]\\\n",
    "    /df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Identify accounts that have separated meters for KW and KWH charges and combine the meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many cases where under the same Building_ID, two meter numbers differ only in the first digit and share the same service date ranges. Usually the larger meter number has zero values in all KW_Charges and the smaller one has zero values in all KWH_Charges. It seems reasonable to combined them.\n",
    "- (Exceptions do exist - some larger meter number have values in both KW and KWH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output:\n",
    "    - df (with consolidated meter numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(['Building_ID', 'Meter_Number']).agg('count').reset_index()[['Building_ID', 'Meter_Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select distinct l.Building_ID, l.Meter_Number, r.Meter_Number\\\n",
    "        from temp l join temp r on l.Building_ID = r.Building_ID and l.Meter_Number > r.Meter_Number \\\n",
    "        where substr(l.Meter_Number, 2, length(l.Meter_number)) == substr(r.Meter_Number, 2, length(r.Meter_number))\"\n",
    "df_meter_mapping = pysql(str1)\n",
    "\n",
    "df_meter_mapping.columns = ['Building_ID', 'Meter_Number_L', 'Meter_Number_S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26.7% of the meter numbers can be mapped to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"select count (distinct Meter_Number_S) as count_redudant_meters\\\n",
    "        from df_meter_mapping\"\n",
    "str2 = \"select count (distinct Meter_Number) as count_meters\\\n",
    "        from temp\"\n",
    "pysql(str1)['count_redudant_meters'][0]/pysql(str2)['count_meters'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if the two meters correspond to KWH_Charges and KW_Charges respectively, by comparing to the df_meter_type table obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(df_meter_mapping, df_meter_type, left_on = ['Building_ID', 'Meter_Number_S']\\\n",
    "         , right_on = ['Building_ID', 'Meter_Number'], how = 'left')\\\n",
    "        [['Building_ID', 'Meter_Number_S', 'count_kwh_only', 'count_kw_only', 'count', 'kwh_only', 'kw_only', 'Meter_Number_L']]\n",
    "\n",
    "temp.columns = ['Building_ID', 'Meter_Number_S', 'count_kwh_only_s', 'count_kw_only_s', 'count_s', 'kwh_only_s', 'kw_only_s',\n",
    "       'Meter_Number_L']\n",
    "\n",
    "temp = pd.merge(temp, df_meter_type, left_on = ['Building_ID', 'Meter_Number_L']\\\n",
    "         , right_on = ['Building_ID', 'Meter_Number'], how = 'left')\\\n",
    "        [['Building_ID', 'Meter_Number_S', 'count_kwh_only_s', 'count_kw_only_s', 'count_s', 'kwh_only_s', 'kw_only_s', 'Meter_Number_L', 'count_kwh_only', 'count_kw_only', 'count', 'kwh_only', 'kw_only']]\n",
    "\n",
    "temp.columns = ['Building_ID', 'Meter_Number_S', 'count_kwh_only_s', 'count_kw_only_s', 'count_s', 'kwh_only_s', 'kw_only_s',\n",
    "       'Meter_Number_L', 'count_kwh_only_l', 'count_kw_only_l', 'count_l', 'kwh_only_l', 'kw_only_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearly all the \"small\" meter_numbers are kw_only meters (they only have non-zero values in kw charges), it seems okay to map them to the \"large\" corresponding meter_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kwh_only_l means the \"larger\" meter_number only has non-zero values in KWH charges; Better doc needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp['kwh_only_l'] == False) & (temp['kw_only_l'] == False)].Meter_Number_S.nunique() / temp.Meter_Number_S.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp['kwh_only_s'] == False) & (temp['kw_only_s'] == False)].Meter_Number_S.nunique() / temp.Meter_Number_S.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp['kwh_only_s'] == True) & (temp['kw_only_s'] == False)].Meter_Number_S.nunique() / temp.Meter_Number_S.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[(temp['kwh_only_s'] == False) & (temp['kw_only_s'] == True)].Meter_Number_S.nunique() / temp.Meter_Number_S.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the meter numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(df, df_meter_mapping, left_on = ['Building_ID', 'Meter_Number'], right_on = ['Building_ID','Meter_Number_S'], how = 'left')\n",
    "temp['Meter_Number_New'] = temp['Meter_Number_L'].combine_first(temp['Meter_Number'])\n",
    "\n",
    "df = temp\n",
    "\n",
    "del(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Meter_Number', 'Meter_Number_L', 'Meter_Number_S'], axis = 1, inplace = True)\n",
    "\n",
    "df.columns = ['Account_Name', 'Location', 'Building_ID', 'Revenue_Month',\n",
    "       'Revenue_Year', 'Service_Start_Date', 'Service_End_Date', '# days',\n",
    "       'Consumption_KW', 'KW_Charges', 'Consumption_KWH', 'KWH_Charges',\n",
    "       'Other_Charges', 'Current_Charges', 'Meter_Number']\n",
    "\n",
    "col_ordered = ['Account_Name', 'Location', 'Building_ID', 'Meter_Number', 'Revenue_Month',\n",
    "       'Revenue_Year', 'Service_Start_Date', 'Service_End_Date', '# days',\n",
    "       'Consumption_KW', 'KW_Charges', 'Consumption_KWH', 'KWH_Charges',\n",
    "       'Other_Charges', 'Current_Charges']\n",
    "\n",
    "df = df[col_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter_mapping.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_meter_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics regarding zero-values and meter types - 2nd time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select Building_ID, Meter_Number \\\n",
    "        , sum(case when KWH_Charges == 0 and KW_Charges > 0 then 1 else 0 end) as count_kw_only \\\n",
    "        , sum(case when KW_Charges == 0 and KWH_Charges > 0 then 1 else 0 end) as count_kwh_only \\\n",
    "        , sum(Current_Charges) as total_current_charges \\\n",
    "        , count(*) as count \\\n",
    "        from df \\\n",
    "        group by df.Building_ID, df.Meter_Number\"\n",
    "df_meter_type = pysql(str1)\n",
    "\n",
    "\n",
    "df_meter_type['kwh_only'] = ((df_meter_type['count_kwh_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kw_only'] == 0)\n",
    "df_meter_type['kw_only'] = ((df_meter_type['count_kw_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kwh_only'] == 0)\n",
    "\n",
    "#### check the meters\n",
    "\n",
    "print(\"perc of kw_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kw_only'] == 1) & (df_meter_type['kwh_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 1) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_and_kw meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 0) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "\n",
    "#### check the building_ids\n",
    "\n",
    "a = df_meter_type[df_meter_type['kwh_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "b =  df_meter_type[df_meter_type['kw_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "a.columns = ['Building_ID', 'Count']\n",
    "b.columns = ['Building_ID', 'Count']\n",
    "\n",
    "print(\"perc of buildings with both kw_only and kwh_only meters:\", \\\n",
    "     \"{:.2%}\".format(pd.merge(a, b, on = 'Building_ID', how = 'inner').shape[0] \\\n",
    "/ df_meter_type.groupby(['Building_ID']).agg('count').reset_index().shape[0]))\n",
    "\n",
    "\n",
    "#### Check the statistics of zero-value rows:\n",
    "\n",
    "print(\"perc of rows - current charges of zero:\", \"{:.2%}\".format(df[df['Current_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kw charges of zero:\", \"{:.2%}\".format(df[df['KW_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kwh charges of zero:\", \"{:.2%}\".format(df[df['KWH_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KWH_Charges'] == 0) ^ (df['Consumption_KWH'] == 0)) \\\n",
    "   | ((df['KW_Charges'] == 0) ^ (df['Consumption_KW'] == 0)) ].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - sum of charges inconsistency:\", \\\n",
    "     \"{:.2%}\".format(1 - df[df['Current_Charges'] == df['KWH_Charges'] + df['KW_Charges'] + df['Other_Charges']].shape[0]\\\n",
    "    /df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Find the accounts with switched meter numbers\n",
    "\n",
    "There are Building_ID's whose meter number changed over the years, need to find the mapping and consolidate the meter numbers (In some cases it's a many-to-many mapping, I'm excluding those cases for now)\n",
    "\n",
    "outputs: \n",
    "1. df_multiple_meter_switch (building_id's with many-to-many meter mapping, need to investigate later)\n",
    "2. df (with consolidated meter numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(['Building_ID']).agg({'Meter_Number': 'nunique'}).reset_index()\n",
    "\n",
    "a = a[a[\"Meter_Number\"]>1]\n",
    "\n",
    "a.columns = ['Building_ID', 'Counts']\n",
    "\n",
    "a = pd.merge(a, df, on = 'Building_ID', how = 'inner')[['Building_ID', 'Meter_Number', \"Revenue_Month\"]]\\\n",
    ".groupby(['Building_ID', 'Meter_Number']).agg({'Revenue_Month': ['max','min']}).reset_index()\n",
    "\n",
    "a.columns = a.columns.get_level_values(0)\n",
    "\n",
    "a.columns = ['Building_ID', 'Meter_Number', 'Max_Month', 'Min_Month']\n",
    "\n",
    "a['Max_Month_Next'] = a['Max_Month'].map(lambda x: x + relativedelta(months=+1))\n",
    "a['Min_Month_Prior'] = a['Min_Month'].map(lambda x: x - relativedelta(months=+1))\n",
    "df_switch_meter = a\n",
    "\n",
    "del(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"select l.Building_ID, l.Meter_Number as Meter_Number_E, r.Meter_Number as Meter_Number_L \\\n",
    "        from df_switch_meter l join df_switch_meter r on l.Building_ID = r.Building_ID and l.Meter_Number != r.Meter_Number \\\n",
    "        where l.Max_Month == r.Min_Month_Prior\"\n",
    "a = pysql(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter_switch = pd.DataFrame(a['Building_ID'].value_counts() > 1).reset_index()\n",
    "df_meter_switch.columns = ['Building_ID', 'Dummy']\n",
    "\n",
    "df_single_meter_switch = df_meter_switch[df_meter_switch['Dummy'] == False]\n",
    "df_multiple_meter_switch = df_meter_switch[df_meter_switch['Dummy'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter_switch = pd.merge(a, df_single_meter_switch, on = 'Building_ID', how = 'inner')[['Building_ID', 'Meter_Number_E', 'Meter_Number_L']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14% of the meters can be mapped to another meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter_switch['Meter_Number_E'].count() / df['Meter_Number'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the meter numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(df, df_meter_switch, left_on = ['Building_ID', 'Meter_Number'], right_on = ['Building_ID', 'Meter_Number_E'], how = 'left')\n",
    "a['Meter_Number_New'] = a['Meter_Number_L'].combine_first(a['Meter_Number'])\n",
    "df = a\n",
    "\n",
    "df.drop(['Meter_Number', 'Meter_Number_L', 'Meter_Number_E'], axis = 1, inplace = True)\n",
    "df.columns = ['Account_Name', 'Location', 'Building_ID', 'Revenue_Month',\n",
    "       'Revenue_Year', 'Service_Start_Date', 'Service_End_Date', '# days',\n",
    "       'Consumption_KW', 'KW_Charges', 'Consumption_KWH', 'KWH_Charges',\n",
    "       'Other_Charges', 'Current_Charges', 'Meter_Number']\n",
    "col_ordered = ['Account_Name', 'Location', 'Building_ID', 'Meter_Number', 'Revenue_Month',\n",
    "       'Revenue_Year', 'Service_Start_Date', 'Service_End_Date', '# days',\n",
    "       'Consumption_KW', 'KW_Charges', 'Consumption_KWH', 'KWH_Charges',\n",
    "       'Other_Charges', 'Current_Charges']\n",
    "df = df[col_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multiple_meter_switch.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_multiple_meter_switch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Consolidate data to Building-Meter-Service_Date_Range level\n",
    "After combinging the meter numbers in the 2 steps above, there are cases where 2 rows exist for the same Meter and Service Date ranges (1 row for KW charges, 1 row for KWH charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month', 'Service_Start_Date', 'Service_End_Date']).agg(['count'])['Account_Name'].reset_index()\n",
    "idx = idx[idx['count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx['count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### see the example below, read starting from the 3rd row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Building_ID'] == '70.0 - BLD 01') & (df['Revenue_Year'] == 2013) & ( (df['Meter_Number'] == '8095177') | (df['Meter_Number'] == '8095173'))\n",
    "df[mask].sort_values(['Service_Start_Date', 'Meter_Number']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove the multiple rows by aggregating at building, meter, revenue month, service_date_range level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['Account_Name', 'Location', 'Building_ID', 'Meter_Number',\n",
    "       'Revenue_Month', 'Revenue_Year', 'Service_Start_Date',\n",
    "       'Service_End_Date', '# days']).\\\n",
    "    agg({'Consumption_KW': 'sum', 'KW_Charges': 'sum', 'Consumption_KWH': 'sum', 'KWH_Charges': 'sum', 'Other_Charges': 'sum', 'Current_Charges': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics regarding zero-values and meter types - 3rd time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select Building_ID, Meter_Number \\\n",
    "        , sum(case when KWH_Charges == 0 and KW_Charges > 0 then 1 else 0 end) as count_kw_only \\\n",
    "        , sum(case when KW_Charges == 0 and KWH_Charges > 0 then 1 else 0 end) as count_kwh_only \\\n",
    "        , sum(Current_Charges) as total_current_charges \\\n",
    "        , count(*) as count \\\n",
    "        from df \\\n",
    "        group by df.Building_ID, df.Meter_Number\"\n",
    "df_meter_type = pysql(str1)\n",
    "\n",
    "\n",
    "df_meter_type['kwh_only'] = ((df_meter_type['count_kwh_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kw_only'] == 0)\n",
    "df_meter_type['kw_only'] = ((df_meter_type['count_kw_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kwh_only'] == 0)\n",
    "\n",
    "#### check the meters\n",
    "\n",
    "print(\"perc of kw_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kw_only'] == 1) & (df_meter_type['kwh_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 1) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_and_kw meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 0) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "\n",
    "#### check the building_ids\n",
    "\n",
    "a = df_meter_type[df_meter_type['kwh_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "b =  df_meter_type[df_meter_type['kw_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "a.columns = ['Building_ID', 'Count']\n",
    "b.columns = ['Building_ID', 'Count']\n",
    "\n",
    "print(\"perc of buildings with both kw_only and kwh_only meters:\", \\\n",
    "     \"{:.2%}\".format(pd.merge(a, b, on = 'Building_ID', how = 'inner').shape[0] \\\n",
    "/ df_meter_type.groupby(['Building_ID']).agg('count').reset_index().shape[0]))\n",
    "\n",
    "\n",
    "#### Check the statistics of zero-value rows:\n",
    "\n",
    "print(\"perc of rows - current charges of zero:\", \"{:.2%}\".format(df[df['Current_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kw charges of zero:\", \"{:.2%}\".format(df[df['KW_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kwh charges of zero:\", \"{:.2%}\".format(df[df['KWH_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KWH_Charges'] == 0) ^ (df['Consumption_KWH'] == 0)) \\\n",
    "   | ((df['KW_Charges'] == 0) ^ (df['Consumption_KW'] == 0)) ].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - sum of charges inconsistency:\", \\\n",
    "     \"{:.2%}\".format(1 - df[df['Current_Charges'] == df['KWH_Charges'] + df['KW_Charges'] + df['Other_Charges']].shape[0]\\\n",
    "    /df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Consolidate data to Building-Meter-Revenue_Month level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### only need to work on the cases where multiple rows exist for the same builing_id, meter_number and revenue_month, due to different service_date_ranges, which might be concatenated in many cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month']).agg('count').reset_index().iloc[:, 0:4]\n",
    "temp.columns = ['Building_ID', 'Meter_Number', 'Revenue_Month', 'Row_Counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multiple = pd.merge(df, temp[temp['Row_Counts']  > 1], on = ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'inner').iloc[:, 0:15]\n",
    "df_single = pd.merge(df, temp[temp['Row_Counts']  == 1], on = ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'inner').iloc[:, 0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by building_id, revenue month, meter number\n",
    "df_multiple = df_multiple.sort_values(by = ['Meter_Number', 'Revenue_Month', 'Service_Start_Date'], ascending=[True, True, True])\n",
    "\n",
    "def merge_dates(grp):\n",
    "    # Find contiguous date groups, and get the first/last start/end date for each group.\n",
    "    dt_groups = (grp['Service_Start_Date'] != grp['Service_End_Date'].shift()).cumsum()\n",
    "    return grp.groupby(dt_groups).agg({'Service_Start_Date': 'first', 'Service_End_Date': 'last',\n",
    "        '# days':'sum', 'Consumption_KW':'sum', 'KW_Charges':'sum',\n",
    "       'Consumption_KWH':'sum', 'KWH_Charges':'sum', 'Other_Charges':'sum', 'Current_Charges':'sum'})\n",
    "\n",
    "# Perform a groupby and apply the merge_dates function, followed by formatting.\n",
    "df_multiple_concatenate = df_multiple.groupby(['Account_Name', 'Location', 'Building_ID', 'Meter_Number', 'Revenue_Month', 'Revenue_Year']).apply(merge_dates)\n",
    "df_multiple_concatenate = df_multiple_concatenate.reset_index().drop('level_6', axis = 1)\n",
    "df_multiple_concatenate = df_multiple_concatenate.reset_index().iloc[:, 1:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_multiple_concatenate.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month']).count().reset_index().iloc[:, 0:4]\n",
    "\n",
    "idx.columns = ['Building_ID', 'Meter_Number', 'Revenue_Month', 'Count']\n",
    "\n",
    "idx[idx['Count'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 6 meters have multiple entries under the same Revenue_Month that can't be concatenated. Again they are caused by the separated logging of KWH and KW charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, idx[idx['Count'] > 1], on = ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove them from the working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(df_multiple_concatenate, idx[idx['Count'] > 1], on = ['Building_ID', 'Meter_Number', 'Revenue_Month'], how = 'left')\n",
    "\n",
    "temp = temp[temp.Count.isnull()].iloc[:, 0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the new working dataset df at Building-Meter-Revenue_Month level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_single.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Building_ID', 'Meter_Number', 'Revenue_Month']).agg('count')\\\n",
    ".reset_index()['Account_Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics regarding zero-values and meter types - 4th time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select Building_ID, Meter_Number \\\n",
    "        , sum(case when KWH_Charges == 0 and KW_Charges > 0 then 1 else 0 end) as count_kw_only \\\n",
    "        , sum(case when KW_Charges == 0 and KWH_Charges > 0 then 1 else 0 end) as count_kwh_only \\\n",
    "        , sum(Current_Charges) as total_current_charges \\\n",
    "        , count(*) as count \\\n",
    "        from df \\\n",
    "        group by df.Building_ID, df.Meter_Number\"\n",
    "df_meter_type = pysql(str1)\n",
    "\n",
    "\n",
    "df_meter_type['kwh_only'] = ((df_meter_type['count_kwh_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kw_only'] == 0)\n",
    "df_meter_type['kw_only'] = ((df_meter_type['count_kw_only']/df_meter_type['count']) > 0.9) & (df_meter_type['count_kwh_only'] == 0)\n",
    "\n",
    "#### check the meters\n",
    "\n",
    "print(\"perc of kw_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kw_only'] == 1) & (df_meter_type['kwh_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_only meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 1) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "print(\"perc of kwh_and_kw meters:\", \"{:.2%}\".format(df_meter_type[(df_meter_type['kwh_only'] == 0) & (df_meter_type['kw_only'] == 0)].shape[0] / df_meter_type.shape[0]))\n",
    "\n",
    "\n",
    "#### check the building_ids\n",
    "\n",
    "a = df_meter_type[df_meter_type['kwh_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "b =  df_meter_type[df_meter_type['kw_only'] == 1].groupby(['Building_ID']).agg('count').reset_index().iloc[:, 0:2]\n",
    "a.columns = ['Building_ID', 'Count']\n",
    "b.columns = ['Building_ID', 'Count']\n",
    "\n",
    "print(\"perc of buildings with both kw_only and kwh_only meters:\", \\\n",
    "     \"{:.2%}\".format(pd.merge(a, b, on = 'Building_ID', how = 'inner').shape[0] \\\n",
    "/ df_meter_type.groupby(['Building_ID']).agg('count').reset_index().shape[0]))\n",
    "\n",
    "\n",
    "#### Check the statistics of zero-value rows:\n",
    "\n",
    "print(\"perc of rows - current charges of zero:\", \"{:.2%}\".format(df[df['Current_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kw charges of zero:\", \"{:.2%}\".format(df[df['KW_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - kwh charges of zero:\", \"{:.2%}\".format(df[df['KWH_Charges'] == 0].shape[0] / df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KWH_Charges'] == 0) ^ (df['Consumption_KWH'] == 0)) \\\n",
    "   | ((df['KW_Charges'] == 0) ^ (df['Consumption_KW'] == 0)) ].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - sum of charges inconsistency:\", \\\n",
    "     \"{:.2%}\".format(1 - df[df['Current_Charges'] == df['KWH_Charges'] + df['KW_Charges'] + df['Other_Charges']].shape[0]\\\n",
    "    /df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KWH_Charges'] == 0) & (df['Consumption_KWH'] != 0))].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - consumption/charge inconsistency:\", \\\n",
    "      \"{:.2%}\".format(df[((df['KW_Charges'] == 0) & (df['Consumption_KW'] != 0))].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - KWH Charges negative:\", \\\n",
    "     \"{:.2%}\".format(df[df['KWH_Charges'] < 0].shape[0]\\\n",
    "    /df.shape[0]))\n",
    "\n",
    "print(\"perc of rows - KW Charges negative:\", \\\n",
    "     \"{:.2%}\".format(df[df['KW_Charges'] < 0].shape[0]\\\n",
    "    /df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Find the gaps between service date ranges\n",
    "\n",
    "We'd like to know how many account have gaps (> 5 days) in their billing windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate service date ranges for each builing_id and  meter_number, across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by building_id, meter number\n",
    "df = df.sort_values(by = ['Building_ID', 'Meter_Number', 'Service_Start_Date'], ascending=[True, True, True])\n",
    "\n",
    "def merge_dates(grp):\n",
    "    # Find contiguous date groups, and get the first/last start/end date for each group.\n",
    "    dt_groups = (grp['Service_Start_Date'] != grp['Service_End_Date'].shift()).cumsum()\n",
    "    return grp.groupby(dt_groups).agg({'Service_Start_Date': 'first', 'Service_End_Date': 'last'})\n",
    "\n",
    "# Perform a groupby and apply the merge_dates function, followed by formatting.\n",
    "df_gap = df.groupby(['Building_ID', 'Meter_Number']).apply(merge_dates)\n",
    "df_gap = df_gap.reset_index().drop('level_2', axis = 1)\n",
    "df_gap = df_gap.reset_index()\n",
    "df_gap.columns = ['rowNum', 'Building_ID', 'Meter_Number', \n",
    "       'Service_Start_Date', 'Service_End_Date']\n",
    "\n",
    "df_gap['nextRowNum'] = df_gap['rowNum'].map(lambda x: x+1)\n",
    "\n",
    "# Join the dataframe with itself to find the gap between service ranges\n",
    "df_gap = pd.merge(df_gap, df_gap[['Building_ID', 'Meter_Number', 'nextRowNum', 'Service_End_Date']],\\\n",
    "        left_on = ['Building_ID', 'Meter_Number', 'rowNum'], right_on = ['Building_ID', 'Meter_Number', 'nextRowNum'], how = 'left')\n",
    "\n",
    "# consecutive days of billing for the same meter number\n",
    "df_gap['consecutive_days'] = \\\n",
    "df_gap[['Service_End_Date_x', 'Service_Start_Date']].apply(lambda x: (x[0] - x[1]).days, axis = 1)\n",
    "\n",
    "# number of days elapsed since the previous service range\n",
    "df_gap['gap_days'] = \\\n",
    "df_gap[['Service_Start_Date', 'Service_End_Date_y']].apply(lambda x: (x[0] - x[1]).days, axis = 1)\n",
    "\n",
    "\n",
    "# Rename and reorder the columns\n",
    "df_gap = df_gap[['Building_ID', 'Meter_Number', 'Service_Start_Date', 'Service_End_Date_x', 'consecutive_days', 'gap_days']]\n",
    "df_gap.columns = ['Building_ID', 'Meter_Number', 'Service_Start_Date', 'Service_End_Date', 'consecutive_days', 'gap_days']\n",
    "\n",
    "df_gap['Building_Meter'] = df_gap['Building_ID'] + df_gap['Meter_Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How frequent does a meter has gaps longer than 5 days through all the years ? ~83.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap[df_gap['gap_days'] >= 5]['Building_Meter'].nunique() / df_gap['Building_Meter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlapping service date ranges - 0.71% of the meter accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_gap['gap_days'] < 0\n",
    "df_gap[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Perc of meters with overlapping service date ranges:\", \"{:.2%}\".format(df_gap[mask]['Building_Meter'].agg('nunique')/df_gap['Building_Meter'].agg('nunique')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap[mask].gap_days.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Building_ID'] == '79.0 - RED HOOK WEST BLD 03') \\\n",
    "& ((df['Meter_Number'] == '6477455')|(df['Meter_Number'] == '6477455') ) \\\n",
    "& (df['Revenue_Year'] == 2011)\n",
    "\n",
    "\n",
    "df[mask].sort_values(['Revenue_Month', 'Service_Start_Date', 'Meter_Number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize gaps by days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_summary = df_gap[df_gap['gap_days'] > 0].groupby('Building_Meter').agg({'consecutive_days':'sum', 'gap_days':'sum'}).reset_index()\n",
    "\n",
    "df_gap_summary['perc_gap'] = df_gap_summary['gap_days']/(df_gap_summary['consecutive_days'] + df_gap_summary['gap_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 29.3% of the meters have % of missing days less than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_summary[df_gap_summary['perc_gap'] < 0.1].shape[0]/ df_gap_summary.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For those who doesn't have gaps longer than 5 days, most of them just have one revenue_month reported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select a.m1 as Building_Meter from \\\n",
    "        (select distinct Building_Meter as m1\\\n",
    "        from df_gap) a \\\n",
    "        left join \\\n",
    "        (select distinct Building_Meter as m2, 1 as ind\\\n",
    "        from df_gap where gap_days >= 5) b \\\n",
    "        on a.m1 == b.m2 where b.ind is null \\\n",
    "        \"\n",
    "a = pysql(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only two metes have almost no gap in all 8 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(a, df_gap, on = 'Building_Meter', how = 'inner').gap_days.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_service_range_gaps\")\n",
    "df_gap_summary.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_service_range_gaps_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Summarize gaps by months (since we found that most of the cases, service date ranges either missed the entire month, or covers the whole month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by building_id, meter number and revenue month\n",
    "df = df.sort_values(by = ['Building_ID', 'Meter_Number', 'Revenue_Month'], ascending=[True, True, True])\n",
    "a = df[['Building_ID', 'Meter_Number', 'Revenue_Month']]\n",
    "a.loc[:, 'Next_Revenue_Month'] = a['Revenue_Month'].map(lambda x: x + relativedelta(months=+1))\n",
    "\n",
    "def merge_months(grp):\n",
    "    # Find contiguous date groups, and get the first/last start/end date for each group.\n",
    "    dt_groups = (grp['Revenue_Month'] != grp['Next_Revenue_Month'].shift()).cumsum()\n",
    "    return grp.groupby(dt_groups).agg({'Revenue_Month': 'first', 'Next_Revenue_Month': 'last'})\n",
    "\n",
    "# Perform a groupby and apply the merge_dates function, followed by formatting.\n",
    "df_gap_month = a.groupby(['Building_ID', 'Meter_Number']).apply(merge_months)\n",
    "df_gap_month = df_gap_month.reset_index().drop('level_2', axis =1)\n",
    "\n",
    "df_gap_month.columns = ['Building_ID', 'Meter_Number', \n",
    "       'Revenue_Month_Start', 'Revenue_Month_End']\n",
    "\n",
    "df_gap_month.loc[:, 'Consecutive_Months'] = \\\n",
    "(df_gap_month['Revenue_Month_End'].dt.year - df_gap_month['Revenue_Month_Start'].dt.year) * 12 + \\\n",
    "(df_gap_month['Revenue_Month_End'].dt.month - df_gap_month['Revenue_Month_Start'].dt.month)\n",
    "\n",
    "df_gap_month['Building_Meter'] = df_gap_month['Building_ID'] + df_gap_month['Meter_Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(df.groupby(['Building_ID', 'Meter_Number']).agg({'Revenue_Month':'max'}).reset_index() \\\n",
    ", df.groupby(['Building_ID', 'Meter_Number']).agg({'Revenue_Month':'min'}).reset_index() \\\n",
    ", on = ['Building_ID', 'Meter_Number'], how = 'inner' \\\n",
    ")\n",
    "\n",
    "\n",
    "a.columns = ['Building_ID', 'Meter_Number', 'Revenue_Month_max', 'Revenue_Month_min']\n",
    "\n",
    "a.loc[:, 'Span_Months'] = \\\n",
    "(a['Revenue_Month_max'].dt.year - a['Revenue_Month_min'].dt.year) * 12 + \\\n",
    "(a['Revenue_Month_max'].dt.month - a['Revenue_Month_min'].dt.month) + 1\n",
    "\n",
    "df_gap_month_summary = \\\n",
    "pd.merge(df_gap_month.groupby(['Building_ID', 'Meter_Number']).agg({'Consecutive_Months':'sum'}).reset_index()\\\n",
    ", a, on = ['Building_ID', 'Meter_Number'], how = 'inner')\n",
    "\n",
    "del(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Building_ID', 'Meter_Number', 'Consecutive_Months', 'Span_Months']\n",
    "df_gap_month_summary = df_gap_month_summary[cols]\n",
    "\n",
    "df_gap_month_summary.loc[:, 'Consecutive_Months_Perc'] = \\\n",
    "df_gap_month_summary['Consecutive_Months'] / df_gap_month_summary['Span_Months']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_revenue_month_gaps\")\n",
    "df_gap_month_summary.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_revenue_month_gaps_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Combine rows to the Building-Meter-Month level and Building-Month level; add new aggregation metrics\n",
    "\n",
    "We need to analyze anamolous values of charges and consumptions at the Building-Meter-Month level and Building-Month level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_meter = df\n",
    "\n",
    "df_combined_building = pd.pivot_table(df, values = ['Current_Charges','Consumption_KWH', 'KWH_Charges',\\\n",
    "       'Consumption_KW', 'KW_Charges', 'Other_Charges'], index=['Account_Name', 'Location', 'Building_ID',\n",
    "       'Revenue_Month'], aggfunc = np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_meter['Total_Charges'] = df_combined_meter['KW_Charges'] + df_combined_meter['KWH_Charges']\n",
    "df_combined_meter['Total_Energy_Rate'] = df_combined_meter['Total_Charges']/df_combined_meter['Consumption_KWH']\n",
    "\n",
    "df_combined_meter['Building_Meter'] = df_combined_meter['Building_ID'] + df_combined_meter['Meter_Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_building['Total_Charges'] = df_combined_building['KW_Charges'] + df_combined_building['KWH_Charges']\n",
    "df_combined_building['Total_Energy_Rate'] = df_combined_building['Total_Charges']/df_combined_building['Consumption_KWH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Save the cleaned data to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data after general data cleansing\n",
    "df_orig.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_original_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data at Building_ID, Meter_Number, Revenue_Month level\n",
    "df.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_CleanedDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data at Building_ID, Meter_Number, Revenue_Month level\n",
    "df_combined_meter.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_combined_meter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data at Building_ID, Meter_Number level\n",
    "df_combined_building.to_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_combined_building\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To continue the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as pdsql\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Setup matplotlib to display in notebook:\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_original_dataset\")\n",
    "\n",
    "df = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_CleanedDF\")\n",
    "\n",
    "df_combined_meter = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_combined_meter\")\n",
    "df_combined_building = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_combined_building\")\n",
    "\n",
    "df_gap = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_service_range_gaps\")\n",
    "df_gap_summary = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_service_range_gaps_summary\")\n",
    "\n",
    "df_gap_month = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_revenue_month_gaps\")\n",
    "df_gap_month_summary = pd.read_pickle(\"../output/NYCHA_Electricity_2010_to_2018_df_revenue_month_gaps_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "str1 = \"select count(*) \\\n",
    "        from df \\\n",
    "        \"\n",
    "temp = pysql(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many meters per building?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Building_ID').agg({'Meter_Number':'nunique'}).reset_index()['Meter_Number'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Consumption_KWH\",  \"Consumption_KW\", \"Current_Charges\", \"KWH_Charges\", \"KW_Charges\", \"Other_Charges\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the billing day gaps per meter per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gaps'] = (df['Service_End_Date'] - df['Service_Start_Date']).dt.days\n",
    "\n",
    "df['gaps'] = df['gaps'].map(lambda x: max(0, 31-x))\n",
    "\n",
    "df.gaps.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gaps'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gaps'] > 5].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of gap days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = np.random.randn(500)\n",
    "# x1 = np.random.randn(500)+1\n",
    "\n",
    "trace1 = go.Box(\n",
    "#     x=df[(df['KW_Charges'] == 0) & df['Consumption_KW'] != 0]['Consumption_KW'], \n",
    "    x = df['gaps'], \n",
    "    opacity=0.75\n",
    ")\n",
    "# trace2 = go.Histogram(\n",
    "#     x=x1,\n",
    "#     opacity=0.75\n",
    "# )\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution for gap months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month_summary['Consecutive_Months_Perc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month_summary[df_gap_month_summary['Consecutive_Months_Perc'] >= .9].shape[0] / df_gap_month_summary['Consecutive_Months_Perc'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month_summary[df_gap_month_summary['Consecutive_Months_Perc'] == 1].shape[0] / df_gap_month_summary['Consecutive_Months_Perc'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Building_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_month_summary[df_gap_month_summary['Consecutive_Months_Perc'] == 1]['Building_ID'].value_counts() / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Histogram(\n",
    "#     x=df[(df['KW_Charges'] == 0) & df['Consumption_KW'] != 0]['Consumption_KW'], \n",
    "    x = df_gap_month_summary['Consecutive_Months_Perc']\n",
    "    , opacity=0.75\n",
    "    , nbinsx = 100\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trendline of data completeness by year-month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_combined_meter.groupby(['Revenue_Month']).agg({'Building_Meter':'nunique'}).reset_index()\n",
    "temp.columns = ['Revenue_Month', 'meter_counts']\n",
    "temp['meter_perc'] = round(temp['meter_counts'] / df_combined_meter.Building_Meter.nunique(), 4)\n",
    "temp = temp.sort_values('Revenue_Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = temp.Revenue_Month,\n",
    "    y = temp.meter_perc\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Trend Line of Data Compleness - % of Accounts with data available in that month',\n",
    "    yaxis=dict(\n",
    "#         title='% of Accounts with data available',\n",
    "        tickformat=\".1%\"\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO - Check where df_combined_meter['Total_Charges'] < 0 or df_combined_meter['Consumption_KWH'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_combined_meter['Consumption_KWH'] > 0) & (df_combined_meter['Total_Charges'] > 0)\n",
    "\n",
    "mask = df_combined_meter['Consumption_KWH'] > 0\n",
    "temp = df_combined_meter[mask].groupby(['Revenue_Month']).agg({\\\n",
    "        'Total_Charges':'mean', 'Total_Energy_Rate': 'mean', 'KWH_Charges':'mean', 'KW_Charges':'mean'}).reset_index()\n",
    "\n",
    "temp.columns = ['Revenue_Month', 'Total_Charges', 'Total_Energy_Rate', 'KWH_Charges', 'KW_Charges']\n",
    "\n",
    "temp = temp.sort_values('Revenue_Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend Line of Average Energy Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trace\n",
    "\n",
    "# Create traces\n",
    "trace1 = go.Scatter(\n",
    "    x = temp.Revenue_Month,\n",
    "    y = temp.Total_Charges,\n",
    "#     mode = 'lines',\n",
    "    name = 'Avg. Total Charge'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = temp.Revenue_Month,\n",
    "    y = temp.Total_Energy_Rate,\n",
    "#     mode = 'lines+markers',\n",
    "    name = 'Avg. Total Charge Rate', \n",
    "    yaxis='y2'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Trend Line of Average Energy Charges',\n",
    "    yaxis=dict(\n",
    "        title='Avg. Total Charges($)',\n",
    "        tickformat=\",\"\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Avg. Total Charge Rates($/KWH)',\n",
    "        titlefont=dict(\n",
    "            color='rgb(148, 103, 189)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(148, 103, 189)'\n",
    "        ),\n",
    "#         tickformat=\".2%\",\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    legend=dict(x=-.1, y=1.2)\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend Line of Average KW and KWH Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a trace\n",
    "\n",
    "# Create traces\n",
    "trace1 = go.Scatter(\n",
    "    x = temp.Revenue_Month,\n",
    "    y = temp.KWH_Charges,\n",
    "#     mode = 'lines',\n",
    "    name = 'Avg. KWH Charges'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = temp.Revenue_Month,\n",
    "    y = temp.KW_Charges,\n",
    "#     mode = 'lines+markers',\n",
    "    name = 'Avg. KW Charges', \n",
    "    yaxis='y2'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Trend Line of Average KW and KWH Charges',\n",
    "    yaxis=dict(\n",
    "        title='Avg. KWH Charges($)',\n",
    "        tickformat=\",\"\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Avg. KW Charges($)',\n",
    "        titlefont=dict(\n",
    "            color='rgb(148, 103, 189)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(148, 103, 189)'\n",
    "        ),\n",
    "        tickformat=\",\",\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    legend=dict(x=-.1, y=1.2)\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A with Linnea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. why would \"Consumption_KW\" be zero?\n",
    "    - KW and KWH should be both positive, unless there are some related bills that already covers it\n",
    "    - Maybe one account was separated into multiple meters?\n",
    "2. What's the \"Other Charges\"?\n",
    "    - negative values to adjust for the payments from previous month\n",
    "    - taxes, fee for meter-reading, little fees charged by utilities and states (e.g. system benefit charge), credit (state got a better deal after charging the clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Statistical & Graphical Analysis on the combined datasets\n",
    "2. Summarize all types of entries that doesn't make sense; flag and ignore them\n",
    "   - Cases where other == kw and kwh == 0, why?\n",
    "   - Cases where other == current and (kw!=0 or kwh != 0)\n",
    "   - Negative values in KWH, KW\n",
    "   - Inconsistency between consumption & charges\n",
    "   - KW charge is offset by negative \"other charge\" (16.7%)\n",
    "   - Meter accounts that only have non-zero values in either KW (0.8%) or KWH (16.9%) charges\n",
    "3. Calendarie the bills (calculate avg. daily cost and consumption and multiple by # of days)\n",
    "4. Starting from 2015, does data quality get better? less meters are missing data? (Government required companies to submit utility data since that time)\n",
    "5. January are more likely to miss data. Why? Check if that's true.\n",
    "6. Check the relationship between Building_ID and Account_Name. Are they 1-on-1 mapping?\n",
    "6. Check anomalies in the following order\n",
    "    - KWH (consumption) .. only compare where there are months of data (ignore the gap month), or we can also use usage per day and then exclude the days with no consumption(instead of using the pro-rated value)\n",
    "    - KWH_Charges\n",
    "    - KW (capacity) consumption and charges (difference in daytime vs. nighttime, summer vs. winter, whole summer is at capacity, we will have really high charges for summer capacity use) (Later Metrics defined below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Later Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) total capacity (kW) for all the meters for the month (building level aggregate)\n",
    "\n",
    "2) Max kW value for the month (both building level and account level)\n",
    "\n",
    "3) Max kW for each meter for the previous 12 months\n",
    "\n",
    "4) Sum of the Max kW for each individual meter\n",
    "\n",
    "5) The variance of Total Charge (sum of KWH_charge and KW_charge) at both account level and building level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge case examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Other_Charges'] != 0) & (df['Current_Charges'] == df['Other_Charges']) & (~((df['KWH_Charges'] == 0) & (df['KW_Charges'] == 0) \\\n",
    "  & (df['Consumption_KWH'] == 0) & (df['Consumption_KW'] == 0)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
